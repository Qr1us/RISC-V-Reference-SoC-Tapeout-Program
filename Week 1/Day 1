
🏆 #IIT Gandhinagar – VSD RISC-V SoC Tapeout Program

image
🚀 Overview

A silicon-proven, open-source SoC design journey where I learned the complete RTL-to-GDS flow on Sky130 PDK, starting from Verilog RTL, simulation, synthesis, optimizations, GLS, and tapeout methodologies. This program by VSD and IIIT Gandhinagar gave me hands-on exposure to industry-grade open-source EDA tools and real fabrication-ready workflows.

🔧 Tools & Technologies Used

        

📚 Key Concepts Learned

📐 Verilog RTL Design & Simulation

RTL coding best practices (blocking vs non-blocking, sensitivity lists)

Writing testbenches with Icarus Verilog

Waveform analysis & debugging with GTKWave

⚙️ Logic Synthesis & Mapping

RTL → Gate-level mapping using Yosys

Flat vs Hierarchical synthesis

Timing-aware synthesis using Sky130 standard cells

⏱ Timing & Libraries

Understanding .lib files (TT, SS, FF)

Setup, hold, and timing arcs with OpenSTA

Effect of timing constraints on synthesis

🔄 Optimizations

Combinational optimizations → boolean simplification, dead logic removal

Sequential optimizations → retiming, removal of unused flops

Power–delay–area trade-offs with different coding styles

🧩 Simulation Mismatches & GLS

Gate-level simulation with back-annotated netlists

Debugging simulation-synthesis mismatches

Blocking vs Non-blocking pitfalls

🏭 RTL to GDSII Flow

Placement & routing with OpenROAD/OpenLane

Layout vs schematic (LVS) checks with Magic + Netgen

DRC, parasitic extraction, and timing closure

Tapeout preparation (Sky130 PDK signoff flow)

🧪 Lab Work Done

Verilog RTL Labs → designed good_mux, counters, flops with proper coding styles

Yosys Synthesis Labs → synthesized mux, flops, if/case constructs

Timing Labs → analyzed .lib, TT/SS/FF timing variations

Optimization Labs → experimented with combinational + sequential optimizations

GLS Labs → verified gate-level netlists and mismatches

RTL-GDS Flow Labs → ran OpenLane flow on synthesized blocks, viewed layouts in Magic/KLayout

📝 Projects & Contributions

RTL & GLS Verification → clean Verilog + gate-level validated designs

Synthesis Reports → timing, area, and power comparisons

Optimization Studies → coding styles impact on synthesis results

RTL-to-GDSII Demo → complete flow on Sky130 using OpenLane

RISC-V Tapeout SoC by VSD and IIT Gandhinagar
Program: RISC-V Reference SoC Tapeout Program
Organized by: VSD & IIT Gandhinagar

Table of Contents
About
Day 1 - Introduction to Verilog RTL Design and Synthesis
Day 2 - Timing libs, Hierarchical vs Flat Synthesis and Efficient Flop Coding Styles
Day 3 - Combinational and Sequential Optimizations
Day 4 - GLS, Blocking vs Non-blocking and Synthesis-Simulation Mismatch
Day 5 - Optimization in Synthesis
About
This repository captures my learning journey through the RISC-V Reference SoC Tapeout Program organized by VSD & IIT Gandhinagar, covering Verilog RTL design, synthesis, labs, and optimization techniques.
Here I’ll document lecture notes, labs, examples, code, screenshots, and reflections as I move through each day.

Day 1 - Introduction to Verilog RTL Design and Synthesis
🔹 Introduction to Open-Source Simulator Iverilog
2-SKY130RTL D1SK1 L1 → Introduction to Iverilog: Design & Testbench

🔹 Simulator

Tool that mimics hardware behavior of HDL (Verilog/SystemVerilog) code.

Lets you check functionality before actual hardware implementation.

🔹 Design

Your RTL/Verilog/SystemVerilog code (the circuit you want to build).

Example: counter, ALU, FSM, etc.

🔹 Testbench

A verification code that stimulates the design with inputs.

Checks whether outputs match expected behavior.

Doesn’t synthesize → used only for simulation.

🔹 How Simulator Works

Compiles both design and testbench.

Executes testbench inputs on design.

Produces output + optional waveform data.

🔹 Icarus Verilog (iverilog) Simulation Flow

Write design + testbench.

Compile: iverilog -o sim_out design.v testbench.v

Run: vvp sim_out

Generate waveform (VCD): $dumpfile("wave.vcd"); $dumpvars; inside testbench.

🔹 VCD File (Value Change Dump)

File format storing signal transitions over time.

Generated during simulation for waveform viewing.

🔹 GTKWave

GUI tool to visualize VCD files.

Run: gtkwave wave.vcd

Lets you see signals, timing, glitches, and debug your logic.

image
🔹 Labs using Iverilog and GTKWave
3-SKY130RTL D1SK2 L1 → Lab1: Introduction to lab
Design And Testbench Of 2:1 Multiplexer (MUX) Using Iverilog & GTKWAVE

Circuit Function: A multiplexer selects one input from multiple inputs based on a control signal.

Working:

If sel = 0 → Output y = a

If sel = 1 → Output y = b

Use Case: Data selection, routing signals, implementing logic functions.

Simulation: Implemented in Verilog with a testbench; simulated using Icarus Verilog (iverilog) and waveform observed in GTKWave.

image
4-SKY130RTL D1SK2 L2 → Lab2: Iverilog & GTKWave (Part 1)

Commands Snapshot Of Implementation Of Commands To Run Mux Design

image
Output Of Mux In GTKWAVE

image
5-SKY130RTL D1SK2 L3 → Lab2: Iverilog & GTKWave (Part 2)

Iverilog Code and Test Bench For Mux Design

image
🔹 Introduction to Yosys and Logic Synthesis
6-SKY130RTL D1SK3 L1 → Introduction to Yosys Yosys
What it is: Open-source framework for RTL synthesis.

Use: Converts Verilog RTL code into a gate-level netlist.

Flow:

Read design (read_verilog)

Run synthesis (synth)

Map to standard cells (abc, dfflibmap)

Write output netlist (write_verilog)

Supports: FPGA flows + ASIC flows (like SKY130).

Why important: First step in RTL → GDSII design flow.

image
🔹 Verifying Synthesis with Icarus Verilog & GTKWave

Step 1: Simulate RTL design with testbench → generate wave.vcd → check logic in GTKWave.

Step 2: Run synthesis in Yosys → get gate-level netlist.

Step 3: Simulate the netlist with same testbench using iverilog → generate new wave.vcd.

Step 4: Compare RTL waveform vs Gate-level waveform in GTKWave.

If both match → synthesis is correct.

image
7-SKY130RTL D1SK3 L2 → Logic Synthesis (Part 1)
🔹 Synthesis

Definition: Process of converting RTL (Register Transfer Level) design into a gate-level representation using standard cell library.

Input:

Verilog RTL code

Technology library (.lib)

Constraints (timing, area, power)

Output:

Gate-level netlist (Verilog)

Reports (timing, area, power)

image
🔹 What is .lib?

A timing library file used in synthesis.

Describes each standard cell:

Function (logic equation)

Timing (delay, setup, hold)

Power consumption

Area

Input to synthesis → helps tool map RTL to real gates.

Why Different Flavours of Gates?

Same logic gate (e.g., NAND2) can have different drive strengths/sizes (like NAND2_X1, NAND2_X2, NAND2_X4).

Reason:

Faster cells → handle high load but consume more area/power.

Slower cells → smaller area, less power, but higher delay.

Synthesis tool chooses based on timing + power constraints.

image
Why We Need Slower Cells?

Hold Violation: Happens when data travels too fast and reaches the next flip-flop before the hold time is satisfied.

Fix: Add delay in the path → one way is to use slower cells instead of fast cells.

Result: Slower cells increase path delay, preventing data from arriving too early → hold violation removed.

8-SKY130RTL D1SK3 L3 → Logic Synthesis (Part 2)
🔹 Fast Cells vs Slow Cells

Feature	Fast Cell	Slow Cell
Delay	Low (quick switching)	High (slower switching)
Power Consumption	High (more dynamic power)	Low (less power)
Area	Large (bigger transistors)	Small (smaller transistors)
Use Case	Critical paths (timing-sensitive)	Non-critical paths (hold/power optimization)
Hold/Setup Effect	May cause hold violations if too fast	Helps fix hold violations by adding delay
🔹 Labs using Yosys and Sky130 PDKs
9-SKY130RTL D1SK4 L1 → Lab3: Yosys Good Mux (Part 1)
Start Yosys yosys

Read your Verilog design read_verilog design.v

Run generic synthesis synth

Map to a standard cell library (example: SKY130) dfflibmap -liberty sky130_fd_sc_hd__tt_025C_1v80.lib abc -liberty sky130_fd_sc_hd__tt_025C_1v80.lib

Check design stat

Write gate-level netlist write_verilog gatelevel.v

Visualize netlist show gatelevel.v

Snap Shot Of Commands To invoke Yosys

image
10-SKY130RTL D1SK4 L2 → Lab3: Yosys Good Mux (Part 2)
image
This is a gate-level netlist view from Yosys showing technology mapping. Here’s a short explanation of the mapping shown in your image:

Inputs & Buffers

i0, i1, and sel are inputs.

Each input goes through a BUF (buffer) which strengthens the signal for further gates.

Mapped Standard Cells

$53 → sky130_fd_sc_hd__clkinv_1 : This is an inverter applied on i0.

$54 → sky130_fd_sc_hd__nand2_1 : This is a 2-input NAND gate applied on i1 and sel.

AOI Gate (Complex Mapping)

$55 → sky130_fd_sc_hd__o21ai_0 : Yosys has mapped the combination of inverter and NAND into a complex gate (OR-AND-Invert) to optimize area/delay.

Inputs A1, A2, B1 are connected from previous cells.

Output Buffer

The final output y goes through a BUF for clean output drive.

✅ Summary:

Yosys converts RTL (like assign y = sel ? i1 : i0) into standard cells.

Simple logic (i0 inverter, i1 NAND) is mapped to basic cells.

Logic combination is optimized into complex cells (o21ai) to reduce area/delay.

Buffers are added for proper driving of signals.

11-SKY130RTL D1SK4 L3 → Lab3: Yosys Good Mux (Part 3)
This file is a gate‑level Verilog netlist written by a synthesis tool after mapping RTL to real SKY130 standard cells.

The top comment records the synthesis tool/version; the module line shows the block name and its ports (inputs like i0, i1, sel and outputs like y).

Internal wire declarations create nets that connect the pins of instantiated cells inside the design.

Instances such as clkinv (inverter), nand2 (2‑input NAND), and o21ai (Y = NAND(OR(A1,A2), B1)) implement the logic using SKY130 HD cells.

Pin maps like .A(sig) or .A1(sig) connect signals to each cell’s pins; each instance drives or consumes the declared wires.

Final assign statements hook the module’s outputs to the appropriate internal nets driven by those cell instances.

Functionally, this particular mix realizes a 2:1 mux structure, so tracing from inputs through these gates to the outputs reveals the mux behaviour

image
Day 2 - Timing libs, Hierarchical vs Flat Synthesis and Efficient Flop Coding Styles
🔹 Introduction to Timing .libs
12-SKY130RTL D2SK1 L1 → Lab4: Introduction to .lib (Part 1)

📌 What is a .lib file?

.lib = Library Exchange Format (LEF/Liberty format) file.

It is an ASCII text file provided by the standard cell vendor.

It describes timing, power, and functional behavior of standard cells used in ASIC/SoC design.

Input to logic synthesis, timing analysis, and PnR tools.

📌 What is present inside .lib?

Cell Definitions

Each standard cell (INV, NAND, Flip-Flop, etc.) has a block.

Functional description of the cell (Boolean equation).

Timing Information

Delay tables (rise/fall delays, setup/hold, clk→Q, etc.).

Slew-dependent and load-dependent delay data.

Power Information

Dynamic power (switching power).

Leakage power.

Internal power.

Operating Conditions (PVT)

Process corner (TT, SS, FF, etc.).

Voltage values.

Temperature values.

Other info

Pin capacitance.

Input/output constraints.

Cell area.

📌 What Is PVT = Process, Voltage, Temperature

Process
Variation due to fabrication (doping, lithography, etc.).

Corners: FF (fast), SS (slow), TT (typical).

Effect:

FF → gates are faster (low delay, more leakage).

SS → gates are slower (high delay, less leakage).

Voltage
Supply voltage fluctuations.

Effect:

High Vdd → faster switching, more power.

Low Vdd → slower switching, less power.

Temperature
Operating environment heat.

Effect:

High Temp → slower switching, more leakage.

Low Temp → faster switching, less leakage.

13-SKY130RTL D2SK1 L2 → Lab4: Introduction to .lib (Part 2)

Snapshot Of .lib file

image image
14-SKY130RTL D2SK1 L3 → Lab4: Introduction to .lib (Part 3)

📌 Cells with Different Features

Same logic cell (e.g., AND gate) can have different variants.

Example: AND2_X1, AND2_X2, AND2_X4 …

X1 → small area, low power, slow.

X4 → larger area, higher power, faster.

Below is the snapshot of different features for same and cell they have different area,power and many more features which vary.

image
🔹 Hierarchical vs Flat Synthesis
15-SKY130RTL D2SK2 L1 → Lab5: Hierarchical vs Flat (Part 1) 📌 Flat vs Hierarchical Synthesis
Flat Synthesis
Entire RTL → flattened into one big netlist.

No module boundaries preserved.

Pros:

Better optimization (tool sees whole design).

Can reduce area/delay.

Cons:

Very large netlist → high runtime + memory.

Debugging harder (lost hierarchy).

Hierarchical Synthesis
RTL modules synthesized separately → then connected at top level.

Module boundaries are preserved.

Pros:

Easier debug & reuse.

Faster runtime, less memory.

Useful for very large designs (SoCs).

Cons:

Less global optimization.

May lead to slightly worse area/timing than flat.

Verilog to code to understand the hierarchical synthesis:

image
It consiste of two modules and their conncetion are shown in Netlist.There is hierarchy between modules so it is hierarchical synthesis.Synthesis is done by tool called yosys.

image
Netlist:

image
16-SKY130RTL D2SK2 L2 → Lab5: Hierarchical vs Flat (Part 2) The Snapshot below shows difference between flat and hierarchical synthesis netlists.
Left side of snapshot is hierarchical synthesis in which hierarchy is preserved as we can see different modules but in right side diagram hierarchy is not preserved so it is flat synthesis.

image
The gatelevel netlist for flat synthesis is shown below

image
📌 Why Module-Level (Hierarchical) Synthesis is Needed

Scalability

Big SoCs have millions of gates → flat synthesis is too heavy (runtime, memory).

Breaking into modules makes synthesis manageable.

Reusability

Standard IPs (e.g., UART, SPI, CPU cores) are pre-synthesized and reused in multiple projects.

No need to resynthesize every time.

Debug & ECO (Engineering Change Order)

Easier to locate and fix issues at module level.

Flat netlist = one giant blob (hard to debug).

Parallel Development

Different teams can work on different modules simultaneously.

Later integrate at top level.

Runtime Efficiency

Hierarchical synthesis reduces compile time drastically.

Useful during iterative design flows.

🔹 Flop Coding Styles & Optimization
17-SKY130RTL D2SK3 L1 → Why Flops? Flop coding styles (Part 1)
📌 What are Flops?

Flop = Flip-Flop (usually D-FF in digital design).

A sequential element that stores 1 bit of data.

Captures input at clock edge (positive or negative).

📌 Why Flops are Used (Advantages)

Avoid Glitches

Combinational logic can create glitches due to unequal path delays.

Flops sample data only at clock edge → glitches in between are ignored.

Synchronization

Aligns signals with the clock → ensures stable timing.

Break Long Paths

Insert flops (pipelining) → reduce critical path delay, improve frequency.

Data Storage

Used to hold states in FSMs, registers, counters, etc.

Reliable Design

Makes design predictable for STA (Static Timing Analysis).

18-SKY130RTL D2SK3 L2 → Flop coding styles (Part 2)
📌 Asynchronous vs Synchronous Reset

Feature	Asynchronous Reset	Synchronous Reset
When it acts	Immediately, independent of clock	Only at active clock edge
Timing	Can reset FF anytime	Reset happens with clock
Glitch sensitivity	May cause glitches if not handled properly	Safer from glitches
Design use	For fast, immediate reset	For predictable, clock-aligned reset
Example in Verilog	always @(posedge clk or posedge rst)	always @(posedge clk) with if (rst)
The snapshot shows different D-FF implementations with synchronous and asynchronous resets, written in Verilog and simulated using Iverilog

image
19-SKY130RTL D2SK3 L3 → Lab: Flop synthesis simulations (Part 1)

Snapshot Of command window to run the flipflop code and simulation.

image
Snapshot of how output of asynchronous dff in gtkwave.

image
Snapshot of how output of synchronous dff in gtkwave.

image
20-SKY130RTL D2SK3 L4 → Lab: Flop synthesis simulations (Part 2)
Snapshot Of commands to run synthesis

image
Gate level netlist of asynchronous reset.

image
Gate level netlist of synchronous reset.

image
21-SKY130RTL D2SK3 L5 → Interesting optimizations (Part 1)
📌 Multiplication by 2ⁿ Optimization

Observation: Multiplying a binary number by 2, 4, 8… (2ⁿ) can be done by simple left shift.

Logic optimization:

Instead of using a multiplier hardware, just append zeros to the LSB.

Example: A * 2 → A << 1 (shift left by 1 bit)

Example: A * 8 → A << 3 (shift left by 3 bits)

Benefit:

No complex multiplier needed.

Saves area, power, and delay.

So we can see clearly in snapshot that no memory cells process are requied.

image
We can clearly see in netlist which is shown below there is no complex hardware these what is the benefit of the optimization.

image
22-SKY130RTL D2SK3 L6 → Interesting optimizations (Part 2)
We can clearly see in netlist which is shown below there is no complex hardware these what is the benefit of the optimization.

image
Day 3 - Combinational and Sequential Optimizations
🔹 Introduction to Optimizations
23-SKY130RTL D3SK1 L1 → Optimizations (Part 1) Combinational Logic Optimization
Definition: Simplifying a digital circuit to reduce the number of gates, levels, or inputs without changing its functionality.

Purpose:

Reduce chip area

Increase speed (lower propagation delay)

Reduce power consumption

Make design cost-effective

Techniques:

Boolean algebra simplification

Karnaugh Map (K-map)

Quine–McCluskey method

Example 1: Multiplication by 2

Original: Use a multiplier to compute Y = A × 2

Optimized: Use a left shift operation: Y = A << 1 (no multiplier needed)

Example 2: Logic simplification

Original: F = A·B + A·~B

Constant Propagation

Definition: Constant propagation is a technique where constant values (0 or 1) in a circuit are used to simplify logic expressions, eliminating unnecessary gates.

Why it is used:

Reduces the number of gates

Simplifies the circuit

Improves speed and power efficiency

Example:

Original logic:

F = A·1 + B·0

Step-by-step simplification using constant propagation:

A·1 = A (anything AND 1 is itself)

B·0 = 0 (anything AND 0 is 0)

So, the optimized logic:

F = A + 0 F = A

Key idea: The constants (1 and 0) “propagate” through the logic and simplify the circuit.

Optimized: F = A

24-SKY130RTL D3SK1 L2 → Optimizations (Part 2)

Sequential Logic Optimization

Definition: Sequential logic optimization improves circuits that have memory elements (flip-flops, latches) along with combinational logic, aiming to reduce area, increase speed, or lower power without changing functionality.

Why it is used:

Reduce critical path delay → faster circuits

Minimize number of flip-flops and gates → smaller area

Optimize power consumption

Improve timing and throughput

Definition: In sequential circuits, constant optimization uses known constant inputs or states to simplify flip-flops and combinational logic that depends on them.

Example:

Suppose we have a sequential circuit with:

DFF1: Q1 = D1 D1 = A · 1

Here, 1 is a constant.

Optimization: D1 = A · 1 = A

Flip-flop still stores Q1 = A, but the AND gate is removed.

Another example (state-based):

State machine table:

Current State Input Next State S0 0 S0 S0 1 S1

If we know input is always 1 during a certain operation, we can propagate this constant:

Remove transitions that depend on 0

Simplify logic for next state computation

Key Idea:

Constants propagate through combinational logic between flip-flops.

Eliminates unnecessary gates and sometimes reduces flip-flop usage.

25-SKY130RTL D3SK1 L3 → Optimizations (Part 3)

Advanced Techniques

Retiming

What: Moving flip-flops across combinational logic to balance path delays.

Why: Reduces the critical path and increases maximum clock frequency.

Example:

Before Retiming: FF -> combinational logic -> FF After Retiming: combinational logic -> FF -> combinational logic

This can allow the circuit to run at a higher clock without changing behavior.

Cloning (or Register Cloning)

What: Duplicating combinational logic blocks so multiple registers can share computations.

Why: Reduces fan-out and load on critical paths, improving timing.

Example:

One logic block feeds 4 FFs → clone the logic so each FF gets its own block → faster clock

Other common sequential optimizations

Clock gating: Turn off flip-flops that are not needed to save power

State encoding optimization: Reduce flip-flop count by smart encoding of states

Pipeline balancing: Evenly distribute logic between stages to improve throughput

Sequential Constant Optimization

🔹 Combinational Logic Optimizations
26-SKY130RTL D3SK2 L1 → Lab6: Combinational Logic (Part 1) Snapshot of Verilog code for and gate using mux
image
Snapshot of Verilog code for or gate using mux

image
Commands window Snapshot of synthesis of & and or gate using mux

image
Gate level netlist of and gate using mux

image
27-SKY130RTL D3SK2 L2 → Lab6: Combinational Logic (Part 2)
Gate level netlist for or gate using mux
image
Verilod code for 3 input and gat using mux

image
Gatelevel netlist for 3 input and gate usign mux

image
🔹 Sequential Logic Optimizations
28-SKY130RTL D3SK3 L1 → Lab7: Sequential Logic (Part 1) Verilog code for dff to understand the sequential logic optimizations

image
Commands to run waveform on gtkwave for dff

image
Snapshot of improper output of dff on gtkwave

image
Gate level netlist for dff using synthesis on yosys

image
29-SKY130RTL D3SK3 L2 → Lab7: Sequential Logic (Part 2) Gate level netlist for design secod case output is optimized becasue be rremoved flip flops from netlist using logic so it is sequential optimization

image
30-SKY130RTL D3SK3 L3 → Lab7: Sequential Logic (Part 3) Verilog code to understand thrid logic optimizations

image
🔹 Sequential Optimizations for Unused Outputs
31-SKY130RTL D3SK4 L1 → Seq Optimisation unused outputs (Part 1) ' Snapshot of command window for observing output of above that thrid design image
Snapshot Output of gtkwave for above design

image
Snapshot of command window to do synthesis of above design

image
Gate level netlist for above design

image
32-SKY130RTL D3SK4 L2 → Seq Optimisation unused outputs (Part 2)
Verilog code for counter is shown in these snapshot image

Snapshot of commands used ton synthesis of conter.These design shows how hardware can be optimized there are unoptimized states in design

image
The below figuare shows gatelevel netlist for counter and for 3 bit counter we usually rquire 3 flipflop but they are some unused state in design then we can do it using one flop also which exactly these lab provided to show

image
Day 4 - GLS, Blocking vs Non-blocking and Synthesis-Simulation Mismatch
🔹 GLS, Synthesis-Simulation Mismatch and Blocking/Non-blocking Statements
33-SKY130RTL D4SK1 L1 → GLS Concepts & Flow using Iverilog
Gate Level Simulation (GLS)

Definition: GLS is simulation of the synthesized gate-level netlist instead of the RTL code.

After synthesis, your design is represented using logic gates (AND, OR, FFs, MUX, etc.) from the technology library.

GLS uses these gate models + optional timing info to verify correctness at the gate level.

🔹 Why GLS is needed?

Equivalence Check: Ensure synthesized netlist behaves the same as RTL.

Timing Verification: With SDF (delays), ensures design meets setup/hold timing.

X-Propagation Checks: Detect uninitialized registers, reset issues, glitches.

Library Mapping: Verify actual cells (from .lib) are functioning as expected.

Confidence before Layout: Ensures no mismatch before place-and-route.

GLS using Icarus Verilog

image
34-SKY130RTL D4SK1 L2 → Synthesis-Simulation Mismatch
🔹 Simulation Mismatches

A simulation mismatch occurs when the RTL simulation result ≠ GLS simulation result.

👉 This usually means the RTL code was written in a way that did not model real hardware correctly, so synthesis interpreted it differently.

Common causes:

Missing sensitivity list (biggest reason in Verilog).

Blocking (=) vs Non-blocking (<=) misuse in sequential logic.

Latch inference due to incomplete assignments.

Uninitialized signals – GLS may show X where RTL showed 0.

Timing differences (RTL ignores delays, GLS includes gate delays).

🔹 Missing Sensitivity Problem

Example (wrong code): always @(a) begin // Missing 'b' in sensitivity list y = a & b; end

In RTL simulation: y will update only when a changes. If b changes alone → no update, so simulation output is stale.

In Synthesis (GLS): Tool infers a combinational gate AND(a, b), so y changes whenever a or b changes.

👉 Result = RTL vs GLS mismatch.

Correct code (fix): always @(*) begin // or always @(a or b) y = a & b; end

@(*) automatically adds all signals in RHS (a, b) → consistent with synthesized hardware.

Now both RTL and GLS match.

🔹 Why this is dangerous?

During RTL sim, you might think design is fine (no bugs).

But after synthesis → GLS shows mismatch (functional failure).

This is why coding guidelines recommend using always @(*) for combinational logic and always @(posedge clk or negedge rst) for sequential logic.

35-SKY130RTL D4SK1 L3 → Blocking vs Non-Blocking Statements in Verilog 🔹 Simulation Mismatches in Blocking vs Non-Blocking Assignments
Blocking (=)
Executes immediately in the given order inside always.

Acts like software statements.

Can cause unintended behavior in RTL sim if used in sequential always blocks.

👉 Example of mismatch

// Sequential block with blocking assignment always @(posedge clk) begin q = d; r = q; // Uses the updated q immediately (in RTL sim) end

RTL Simulation: r gets the new value of d in the same clock cycle (because q updated immediately).

Synthesis/GLS: Hardware is two flip-flops in series (q → r). r should get the old value of q. → Mismatch!

✅ Correct way: use non-blocking (<=) in sequential logic.

Non-Blocking (<=)
Executes in parallel at the end of the always block.

Models real flip-flop behavior.

Ensures all RHS values are sampled first, then updates happen together.

👉 Example (correct)

always @(posedge clk) begin q <= d; r <= q; // r gets old q, as expected end

RTL Simulation: Matches real hardware.

GLS: No mismatch.

🔹 Common Caveats (Gotchas) 🟢 Blocking (=) Caveats

Good for combinational logic (always @(*)) → ensures step-by-step evaluation.

Dangerous in sequential blocks (always @(posedge clk)) → can cause mismatches.

Can lead to simulation race conditions if multiple always blocks depend on same signal.

🔵 Non-Blocking (<=) Caveats

Must be used for sequential logic (FFs).

If used in combinational always blocks, can cause unexpected latches or unintended parallelism.

always @(*) begin y <= a & b; // BAD: synthesizer may infer latch or strange behavior end

Order of statements does not matter (all update in parallel). Sometimes makes debugging harder.

🔹 Quick Rule of Thumb

Combinational logic → use = (blocking).

Sequential (clocked) logic → use <= (non-blocking).

Never mix them in the same always block (unless you really know why).

36-SKY130RTL D4SK1 L4 → Caveats with Blocking Statements
🔹 Disadvantages of Blocking Assignments (=) in Sequential Logic

One-Cycle Mismatch

RTL sim: values propagate instantly inside same always block.

Real circuit: flip-flops update only on clock edge → output lags by 1 cycle.

❌ Causes wrong pipelining (data looks 1 cycle early in sim).

Race Conditions

If multiple always blocks use blocking assignments, execution order in sim matters.

Real hardware updates in parallel → mismatch.

Hard Debugging

Sim shows design working fine, but on FPGA/ASIC, behavior is different → time lost in bring-up.

🔹 Disadvantages of Non-Blocking Assignments (<=) in Combinational Logic

Latch Inference

Incomplete assignments with <= can create unintended storage elements.

❌ Extra area, timing failures, higher power.

Glitchy Outputs

Since updates happen at end of block, combinational outputs may hold old values → wrong intermediate behavior.

Loss of Ordering Control

In combinational blocks, sometimes order of execution matters (e.g., priority logic).

With <=, all updates happen in parallel → wrong circuit implementation.

🔹 Mixing = and <= in Same Block

❌ Very risky → synthesis tool may still build correct flip-flops, but simulation will show different values depending on ordering.

Leads to unpredictable mismatches → hardest to debug.

🔹 Labs on GLS and Synthesis-Simulation Mismatch
37-SKY130RTL D4SK2 L1 → Lab: GLS Synth-Sim Mismatch (Part 1)
Verilog code to Understand Ternary operator working

image
Gatelevel netlist for ternary oprator

image
38-SKY130RTL D4SK2 L2 → Lab: GLS Synth-Sim Mismatch (Part 2)
GLS output for Ternary mux on gtk wave

image
🔹 Labs on Synth-Sim Mismatch for Blocking Statements
39-SKY130RTL D4SK3 L1 → Lab: Synth-Sim mismatch (Blocking, Part 1)

Verilog code to showcase simulation mismatch and how it cna affect our design

image
Output of GTKWAVE Of above design and it shows that mux in above design working as flipflop not like mux output is not sensitive to inputs it is only depends on the select it will change only if there is activity on select.

image The snapshot shows the output is make valid using GLS simulation to remove simulation mismatch.In the figuare output is changing when inputs and sel is changing while in previous case it was depending upon sel only image
40-SKY130RTL D4SK3 L2 → Lab: Synth-Sim mismatch (Blocking, Part 2)
Verilog code to show simulation mismatch due to the blocking statements.

image
As you can see output of above verilog code on gtkwave it is not the proper output because of simulation mismatch becasue we are getting low output when input a is high it should be low that is due to simulation mismatch

image
These is the output of GLS on gtkwave we can see the simulation mismatches which where there in previous case are removed and we are getting high output when a input is high that we can clearly see in ouput below

image
Day 5 - Optimization in Synthesis
🔹 If-Case Constructs
41-SKY130RTL D5SK1 L1 → IF-CASE Constructs (Part 1)
🔹 if-else Construct

Used inside always blocks to describe conditional behavior.

Example:

always @(*) begin if (sel) y = a; else y = b; end

👉 Synthesizer infers a MUX (y = sel ? a : b).

🔹 Inferred Latch with if-else

Latch gets inferred when not all cases assign a value to the output in a combinational block.

Example (bug):

always @(*) begin if (en) y = d; // What if en = 0? → y not assigned end

👉 Synthesis assumes you want y to hold its old value → infers a latch.

Problems caused by latch:

Extra area + power.

Timing closure difficulties.

May cause unintended storage behavior.

🔹 Correct way

Always cover all cases in if-else:

always @(*) begin if (en) y = d; else y = 0; // Or some default value end

Or give a default assignment before condition:

always @(*) begin y = 0; // default if (en) y = d; end

42-SKY130RTL D5SK1 L2 → IF-CASE Constructs (Part 2) 🔹 Case Construct
General form:

always @(*) begin case (sel) 2'b00: y = a; 2'b01: y = b; 2'b10: y = c; default: y = d; endcase end

👉 Synthesizer infers a MUX (y = f(sel)).

🔹 Caveats if default is Missing

Inferred Latches
If not all cases are covered and no default, then for some sel values → y not assigned → latch inferred.

always @(*) begin case (sel) 2'b00: y = a; 2'b01: y = b; // Missing sel=2'b10, 2'b11 → y holds old value = LATCH endcase end

Simulation Mismatch
RTL sim may leave y as X for uncovered cases,

Synthesis may optimize differently (e.g., latch or don’t-care). 👉 GLS vs RTL mismatch.

Unintended Priority
If multiple case statements without default interact, synthesis might create priority logic you didn’t want.

Optimization Ambiguity
Tools may treat missing cases as don’t-cares.

Sometimes helpful for optimization, but dangerous → can cause wrong circuit if don’t-cares actually occur in real operation.

🔹 Best Practices

Always use default in case for combinational logic.

Or initialize outputs with a default assignment before case.

always @(*) begin y = 0; // default case (sel) 2'b00: y = a; 2'b01: y = b; 2'b10: y = c; default: y = d; endcase end

For FSMs, default can safely send design to a known reset state if an invalid state occurs.

43-SKY130RTL D5SK1 L3 → IF-CASE Constructs (Part 3) 🔹 Partial Assignment in case
When inside a case block you assign only some signals, and leave others untouched, the untouched signals will retain their previous value. 👉 This causes latch inference in combinational logic.

⚠️ Example (Bug – Partial Assignment) reg [3:0] y;

always @(*) begin case (sel) 2'b00: y[0] = a; // Only bit 0 assigned 2'b01: y[1] = b; // Only bit 1 assigned default: ; // y[2] and y[3] never assigned endcase end

For some cases, parts of y are not assigned → synthesizer adds latches to hold their old values.

✅ Correct Way (Full Assignment)

Assign entire signal in every case

always @(*) begin case (sel) 2'b00: y = {3'b000, a}; 2'b01: y = {2'b00, b, 1'b0}; default: y = 4'b0000; endcase end

Or give default assignment before case

always @(*) begin y = 4'b0000; // default → no latch case (sel) 2'b00: y[0] = a; 2'b01: y[1] = b; endcase end

🔹 Caveats of Partial Assignment

Latch Inference → increases area, power, timing issues.

Simulation vs Synthesis Mismatch → simulation may show X while synthesis infers latch.

Unpredictable Hardware Behavior if unassigned bits are used later.

Hard Debugging → design seems fine in sim but fails in GLS/FPGA.

🔹 Labs on Incomplete If-Case
44-SKY130RTL D5SK2 L1 → Lab: Incomplete IF (Part 1)
Verilog code to understand errors can occur if not give all conditions to if else

image
Diagram below shows that circuit is not working proper because we have just give condition when io is high but not mentioned what to do if io is low so due to these we get simulation mismatch is which shown on output of gtkwave for above design

image
Commands snapshot To run synthesis of above design on yosys tool.

image
These the gatelevel netlist for incomplete if due to not giving all conditions we got d flipflop is infered in place of mux these due to if else cavets

image
45-SKY130RTL D5SK2 L2 → Lab: Incomplete IF (Part 2)
Verilog code to understand second issue due to not giving all conditions or cavets due to if eles construct

image
So below screenshot shows that we are not getting proper output on gtkwave for above design becasue we have not mentioned all the conditions of if else

image
So the following figuare shows netlist for second design.It shows that we get latch in place of muxes becasue of we have not mentioned else conditions for if

image
🔹 Labs on Incomplete Overlapping Case
46-SKY130RTL D5SK3 L1 → Lab: Incomplete Overlapping Case (Part 1) Verilog code for case construct on Icarus Verilog
image
Functional simulation for case construct on gtkwave it shows that if we not give all conditions in case then we will not get proper output or output is latched.In the above figuare we can clearly see that we are getting proper output for i0 and i1 but in case of i2 and i3 ouput is not getting properly it is only becasue we have not mentioned what do for these in case statement written in verilog code

image
The above figuare shows the gate level netlist for case construct

image
47-SKY130RTL D5SK3 L2 → Lab: Incomplete Overlapping Case (Part 2)
It is the verilog to handle case construct using default statement to avoid improper working of circuit it will help to make proper wworking of circuit

image
Following is Simulation of case construct handling using default statement on gtkwave to maintain proper working of circuit.

image
The following is gatelevel netlist of above design it clearly shows that if we use default condition it infer will not infer latch so it is importent to use default to maintain proper output for unused states otherwise there might be possibility of lock out due to it

image
48-SKY130RTL D5SK3 L3 → Lab: Incomplete Overlapping Case (Part 3)
The below image shows the code verilog code to understand partial dependency issues in case construct

image
The Figuare below shows the gate level netlist for above verilog code

image
49-SKY130RTL D5SK3 L4 → Lab: Incomplete Overlapping Case (Part 4)
The verilog code for case construct if we mention same conditions.Ex like sel =00 twice or we use sel=1? so synthesizer will get confused what to use chose and it will affect the out pur it is called bad case construct so we need avoid repetition of sel inputs to generate desired output

image
Snapshots of commands to do synthesis of case construct for bad case construct

image
🔹 For Loop and For Generate
50-SKY130RTL D5SK4 L1 → For Loop & For Generate (Part 1)
for Loop in Procedural Blocks (always, initial)

Used for simulation/behavioral modeling.

Executes sequentially during simulation.

Example:

always @(posedge clk) begin for (i=0; i<8; i=i+1) shift_reg[i] <= shift_reg[i-1]; end

Applications:

Repeated assignments inside always block

Testbench stimulus

Compact behavioral code

Hardware is not replicated — just sequential description.

🔹 generate for Loop

Used in RTL synthesis to replicate hardware.

Works at elaboration/compile-time, not at run-time.

Example:

genvar i; generate for (i=0; i<8; i=i+1) begin : gen_block dff d1 (.d(d[i]), .clk(clk), .q(q[i])); end endgenerate

Applications:

Instantiating multiple modules (e.g., N flip-flops, adders)

Parametric hardware design (scalable design)

Creates real hardware copies, unlike procedural for.

Aspect Procedural for (always/initial) Generate for Execution Time Run-time (simulation) Compile/elaboration time Purpose Compact coding in behavior Replicate hardware structurally Use Case Loops inside processes, testbenches Multiple module instances, parametric RTL

Aspect	Procedural for (always/initial)	Generate for
Execution Time	Run-time (simulation)	Compile/elaboration time
Purpose	Compact coding in behavior	Replicate hardware structurally
Use Case	Loops inside processes, testbenches	Multiple module instances, parametric RTL
51-SKY130RTL D5SK4 L2 → For Loop & For Generate (Part 2)
🔹 Proper Uses of generate for

Replicating Modules/Hardware

Example: Creating an N-bit register by instantiating multiple D-FFs.

genvar i; generate for (i=0; i<N; i=i+1) begin : reg_array dff d1 (.d(d[i]), .clk(clk), .q(q[i])); end endgenerate

Bus/Array of Adders, Multipliers, Comparators

Example: Ripple-carry adder → chain of 1-bit full adders.

genvar j; generate for (j=0; j<N; j=j+1) begin : adder_chain full_adder fa (.a(a[j]), .b(b[j]), .cin(c[j]), .s(sum[j]), .cout(c[j+1])); end endgenerate

Parameterized & Scalable Designs

Change N parameter → hardware scales automatically.

Used in IP blocks like ALUs, multipliers, memories.

Conditional Hardware Generation

With if-generate inside → include/exclude hardware based on parameters.

generate if (WIDTH == 8) begin // 8-bit version hardware end else begin // 16-bit version hardware end endgenerate

52-SKY130RTL D5SK4 L3 → For Loop & For Generate (Part 3)
Normal for (inside always / initial)

Runs at simulation time.

Used for iterative assignments/operations.

Does not replicate hardware → just a compact way to describe behavior.

Example: shift register update inside an always block.

🔹 Generate for (outside always, with genvar)

Runs at elaboration/compile time.

Used to replicate hardware modules/blocks.

Creates real hardware instances (N copies).

Example: generate N flip-flops, adders, multiplexers.

🔹 Labs on For Loop and For Generate
53-SKY130RTL D5SK5 L1 → Lab: For & For Generate (Part 1)
The following is the verilog code to understand use case of for loop inside always block it it works

image
The below diagram shows the output verilog code for loop inside always block in gtkwave.

image
54-SKY130RTL D5SK5 L2 → Lab: For & For Generate (Part 2)
🔹 Why for is preferred over case

Scalability → for easily handles large bit-widths (e.g., 128-bit bus), while case becomes too long.

Parameterization → works smoothly with parameters/generics for flexible designs.

Compact Code → avoids repetitive code that case would require.

Less Error-Prone → no risk of missing cases (which can infer latches).

Synthesis Friendly → tools unroll for into equivalent hardware automatically.

Verilog code for demux using case

image
Verilog code for demux using for loop it is prefered over case for large demux like 1:256 mux and larger than these also

image
Output of demux on gtkwace using case statement

image
55-SKY130RTL D5SK5 L3 → Lab: For & For Generate (Part 3)
🔹 Why prefer for-generate over manual structural instantiation

Scalability → avoids writing hundreds of repetitive module instances manually.

Parameterization → design size changes automatically with a parameter (N).

Readability & Maintainability → much cleaner and less error-prone code.

Consistency → guarantees identical hardware replication without copy-paste mistakes.

The following is the code for ripple carry adder using for generate it is very useful in case large design help us to reduce the thousands line of code

image
56-SKY130RTL D5SK5 L4 → Lab: For & For Generate (Part 4)
It shows the output of full adder implemented using for generate on gtkwave

image
